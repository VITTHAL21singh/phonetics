<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IPA Phonetics Explorer</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for a clean, sharp, cyber look */
        .phoneme-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(60px, 1fr));
            gap: 12px;
        }
        .phoneme-button {
            display: flex;
            flex-direction: column; /* NEW: Stack symbol and example vertically */
            align-items: center;
            justify-content: center;
            width: 90px; /* FIXED: Enforce uniform width for proper fitting */
            height: 70px; /* FIXED: Enforce uniform height */
            padding: 0.5rem 0.25rem; /* Reduced padding for better fit */
            
            font-family: 'Inter', monospace; 
            font-weight: 700;
            border-radius: 4px; /* Reduced rounding for sharpness */
            box-shadow: 0 0 5px rgba(0, 0, 0, 0.5); /* Subtle dark shadow */
            transition: all 0.15s ease-in-out;
            cursor: pointer;
            user-select: none;
            border: 2px solid;
            background-color: #1f2937; /* Dark slate background */
        }
        /* Neon Glow Effect on Hover (Vowels) */
        .vowel {
            border-color: #d946ef; /* Fuchsia-500 */
            color: #f0abfc; /* Fuchsia-300 */
        }
        .vowel:hover {
            border-color: #f0abfc;
            color: white;
            box-shadow: 0 0 15px #f0abfc; 
            transform: scale(1.05); /* Slightly more dramatic hover effect */
        }
        /* Neon Glow Effect on Hover (Consonants) */
        .consonant {
            border-color: #06b6d4; /* Cyan-500 */
            color: #67e8f9; /* Cyan-300 */
        }
        .consonant:hover {
            border-color: #67e8f9;
            color: white;
            box-shadow: 0 0 15px #67e8f9;
            transform: scale(1.05); /* Slightly more dramatic hover effect */
        }
        .loading-ring {
            border: 4px solid rgba(255, 255, 255, 0.2);
            border-top: 4px solid #67e8f9; /* Neon Cyan loading ring */
            border-radius: 50%;
            width: 20px;
            height: 20px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-950 min-h-screen p-4 md:p-8 font-['Inter',_monospace] text-gray-100">

    <!-- Main Application Container -->
    <div class="max-w-4xl mx-auto">
        <h1 class="text-4xl font-extrabold text-cyan-400 mb-2">IPA Phonetics Explorer</h1>
        <p class="text-gray-400 mb-6 md:mb-8">Click any International Phonetic Alphabet (IPA) symbol to hear its pronunciation and see a quick explanation.</p>

        <!-- Loading Indicator & Status Message (Cyan/Neon Themed) -->
        <div id="status-message" class="hidden bg-gray-800 border border-cyan-600 text-cyan-400 px-4 py-3 rounded-md mb-6 shadow-xl" role="alert">
            <div class="flex items-center">
                <div id="loading-spinner" class="loading-ring mr-3 hidden"></div>
                <p id="status-text" class="font-medium"></p>
            </div>
        </div>

        <!-- IPA Chart Sections -->
        <div id="ipa-chart-container" class="space-y-8">
            
            <!-- Vowels (Fuchsia Neon) -->
            <h2 class="text-2xl font-bold text-fuchsia-400 border-b-2 border-fuchsia-600 pb-1">Monophthongs (Vowels)</h2>
            <div id="vowel-grid" class="phoneme-grid">
                <!-- Vowel buttons will be populated here -->
            </div>

            <!-- Consonants (Cyan Neon) -->
            <h2 class="text-2xl font-bold text-cyan-400 border-b-2 border-cyan-600 pb-1 pt-4">Consonants</h2>
            <div id="consonant-grid" class="phoneme-grid">
                <!-- Consonant buttons will be populated here -->
            </div>
        </div>
    </div>

    <!-- Modal for Result Display (Simulating Video/Info Screen) -->
    <div id="result-modal" class="fixed inset-0 bg-gray-900 bg-opacity-90 hidden flex items-center justify-center p-4 z-50">
        <div class="bg-gray-800 border border-cyan-500 rounded-lg shadow-2xl max-w-lg w-full p-6 space-y-4">
            <h3 class="text-3xl font-bold text-cyan-400 border-b border-gray-700 pb-2 flex items-center">
                Symbol: <span id="modal-symbol" class="ml-3 text-fuchsia-400"></span>
                <button id="modal-play-audio" class="ml-4 p-2 bg-cyan-600 text-gray-900 rounded-full hover:bg-cyan-400 transition shadow-lg">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9c2.5 2.5 2.5 6.57 0 9.07m-5.656-7.072l2.121 2.121m-4.242 4.242L12 12m-7.072 0a5 5 0 017.072 0v0z" />
                    </svg>
                </button>
            </h3>
            
            <p id="modal-explanation" class="text-gray-300 text-lg"></p>
            
            <div class="pt-2">
                <p class="font-semibold text-cyan-500">Source:</p>
                <ul id="modal-sources" class="list-disc list-inside text-sm text-gray-500 space-y-1 ml-4">
                    <!-- Sources will be inserted here -->
                </ul>
            </div>

            <button onclick="closeModal()" class="w-full bg-fuchsia-600 text-white font-semibold py-2 rounded-md hover:bg-fuchsia-500 transition shadow-md">
                Close
            </button>
        </div>
    </div>

    <!-- Application Logic and Gemini API Calls -->
    <script>
        // --- Environment Detection ---
        // Determines if we are in the secure canvas environment or running statically (e.g., GitHub Pages).
        const IS_STATIC_HOSTING = typeof __app_id === 'undefined'; 

        // Constants for Gemini API calls (Only used if not static hosting)
        const API_KEY = ""; 
        const SEARCH_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${API_KEY}`;
        const TTS_API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${API_KEY}`;
        const MAX_RETRIES = 5;

        // --- Mock Audio Placeholder ---
        // A simple function to play a beep sound when running statically
        function playMockAudio() {
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const oscillator = audioCtx.createOscillator();
            const gainNode = audioCtx.createGain();

            oscillator.type = 'sine';
            oscillator.frequency.setValueAtTime(440, audioCtx.currentTime); // A4 note
            gainNode.gain.setValueAtTime(0.5, audioCtx.currentTime);
            
            oscillator.connect(gainNode);
            gainNode.connect(audioCtx.destination);
            
            oscillator.start();
            oscillator.stop(audioCtx.currentTime + 0.2); // 200ms duration
        }


        // --- Caching Strategy ---
        const cache = {
            searchInfo: {},
            audioUrls: {} // Stores Object URL for cached audio blob (or 'mock' string)
        };

        // --- Data Structure for IPA Symbols ---
        const ipaSymbols = {
            vowels: [
                { symbol: 'iː', name: 'long E', example: 'sheep', mock_desc: 'High front long vowel, common in "fleece".' },
                { symbol: 'ɪ', name: 'short I', example: 'ship', mock_desc: 'Near-high near-front vowel, common in "kit".' },
                { symbol: 'e', name: 'short E', example: 'red', mock_desc: 'Mid-front vowel, as in "dress".' },
                { symbol: 'æ', name: 'short A', example: 'cat', mock_desc: 'Near-low front vowel, as in "trap".' },
                { symbol: 'ʌ', name: 'short U', example: 'cup', mock_desc: 'Low-mid central vowel, often in stressed short syllables.' },
                { symbol: 'ɑː', name: 'long A', example: 'father', mock_desc: 'Low back long vowel, as in "bath" (UK English).' },
                { symbol: 'ɔː', name: 'long O', example: 'door', mock_desc: 'Mid-back round long vowel, as in "thought".' },
                { symbol: 'ʊ', name: 'short OO', example: 'good', mock_desc: 'Near-high near-back round vowel, as in "foot".' },
                { symbol: 'uː', name: 'long OO', example: 'blue', mock_desc: 'High back round long vowel, as in "goose".' },
                { symbol: 'ə', name: 'Schwa', example: 'about', mock_desc: 'Mid-central unstressed vowel, the most common sound in English.' },
                { symbol: 'aɪ', name: 'Diphthong I', example: 'my', mock_desc: 'A closing diphthong from open to high, as in "price".' },
                { symbol: 'ɔɪ', name: 'Diphthong Oi', example: 'boy', mock_desc: 'A closing diphthong, as in "choice".' },
            ],
            consonants: [
                { symbol: 'p', name: 'P sound', example: 'pen', mock_desc: 'Voiceless bilabial stop, air blocked by both lips then released.' },
                { symbol: 'b', name: 'B sound', example: 'bat', mock_desc: 'Voiced bilabial stop, same as /p/ but with vocal fold vibration.' },
                { symbol: 't', name: 'T sound', example: 'top', mock_desc: 'Voiceless alveolar stop, air blocked by the tongue tip on the ridge.' },
                { symbol: 'd', name: 'D sound', example: 'dog', mock_desc: 'Voiced alveolar stop, same as /t/ but with vocal fold vibration.' },
                { symbol: 'k', name: 'K sound', example: 'cat', mock_desc: 'Voiceless velar stop, air blocked by the tongue back against the soft palate.' },
                { symbol: 'g', name: 'G sound', example: 'go', mock_desc: 'Voiced velar stop, same as /k/ but with vocal fold vibration.' },
                { symbol: 'f', name: 'F sound', example: 'fish', mock_desc: 'Voiceless labiodental fricative, air forced through the gap between lower lip and upper teeth.' },
                { symbol: 'v', name: 'V sound', example: 'van', mock_desc: 'Voiced labiodental fricative, same as /f/ but with vocal fold vibration.' },
                { symbol: 'θ', name: 'Th (voiceless)', example: 'thing', mock_desc: 'Voiceless dental fricative, tongue tip near or between teeth.' },
                { symbol: 'ð', name: 'Th (voiced)', example: 'this', mock_desc: 'Voiced dental fricative, same as /θ/ but with vocal fold vibration.' },
                { symbol: 's', name: 'S sound', example: 'sun', mock_desc: 'Voiceless alveolar fricative (sibilant).' },
                { symbol: 'z', name: 'Z sound', example: 'zoo', mock_desc: 'Voiced alveolar fricative (sibilant), same as /s/ but with vocal fold vibration.' },
                { symbol: 'ʃ', name: 'Sh sound', example: 'ship', mock_desc: 'Voiceless postalveolar fricative, often called "esh".' },
                { symbol: 'ʒ', name: 'Zh sound', example: 'vision', mock_desc: 'Voiced postalveolar fricative, often called "yogh".' },
                { symbol: 'tʃ', name: 'Ch sound', example: 'church', mock_desc: 'Voiceless postalveolar affricate, combination of /t/ and /ʃ/.' },
                { symbol: 'dʒ', name: 'J sound', example: 'judge', mock_desc: 'Voiced postalveolar affricate, combination of /d/ and /ʒ/.' },
                { symbol: 'm', name: 'M sound', example: 'man', mock_desc: 'Voiced bilabial nasal, airflow through the nose, lips closed.' },
                { symbol: 'n', name: 'N sound', example: 'no', mock_desc: 'Voiced alveolar nasal, airflow through the nose, tongue tip on the alveolar ridge.' },
                { symbol: 'ŋ', name: 'Ng sound', example: 'sing', mock_desc: 'Voiced velar nasal, airflow through the nose, tongue back against the soft palate.' },
                { symbol: 'l', name: 'L sound', example: 'love', mock_desc: 'Voiced alveolar lateral approximant, airflow around the sides of the tongue.' },
                { symbol: 'r', name: 'R sound', example: 'run', mock_desc: 'Voiced alveolar or postalveolar approximant (rhotic sound).' },
                { symbol: 'j', name: 'Y sound', example: 'yes', mock_desc: 'Voiced palatal approximant, as in "yes".' },
                { symbol: 'w', name: 'W sound', example: 'wet', mock_desc: 'Voiced labial-velar approximant, a glide starting with rounded lips.' },
                { symbol: 'h', name: 'H sound', example: 'hat', mock_desc: 'Voiceless glottal fricative, airflow through the open glottis.' },
            ]
        };

        // Pre-populate mock data for static hosting
        if (IS_STATIC_HOSTING) {
            ipaSymbols.vowels.forEach(item => {
                cache.searchInfo[item.symbol] = {
                    text: item.mock_desc + " (Mock Data: API calls are disabled for static hosting).",
                    sources: []
                };
                cache.audioUrls[item.symbol] = 'mock'; // Use 'mock' to signal mock playback
            });
            ipaSymbols.consonants.forEach(item => {
                cache.searchInfo[item.symbol] = {
                    text: item.mock_desc + " (Mock Data: API calls are disabled for static hosting).",
                    sources: []
                };
                cache.audioUrls[item.symbol] = 'mock'; // Use 'mock' to signal mock playback
            });
            console.log("Static Hosting Mode: API calls are mocked for GitHub Pages compatibility.");
        }


        // --- UI Initialization ---

        function renderPhonemeButtons() {
            const vowelGrid = document.getElementById('vowel-grid');
            const consonantGrid = document.getElementById('consonant-grid');

            ipaSymbols.vowels.forEach(item => {
                const button = createButton(item, 'vowel');
                vowelGrid.appendChild(button);
            });

            ipaSymbols.consonants.forEach(item => {
                const button = createButton(item, 'consonant');
                consonantGrid.appendChild(button);
            });
        }

        function createButton(item, type) {
            const button = document.createElement('button');
            button.className = `phoneme-button ${type}`;
            button.setAttribute('data-symbol', item.symbol);
            button.setAttribute('data-example', item.example);
            button.setAttribute('title', `Click to hear and learn about the ${item.symbol} sound.`);
            
            button.innerHTML = `
                <span class="text-2xl">${item.symbol}</span>
                <span class="text-xs font-light opacity-75">(${item.example})</span>
            `;
            button.onclick = () => handleSymbolClick(item.symbol, item.example);
            return button;
        }

        window.onload = renderPhonemeButtons;


        // --- Utility Functions for Audio Playback ---

        // Converts base64 to ArrayBuffer
        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        // Converts 16-bit PCM audio data to a WAV file Blob
        function pcmToWav(pcm16, sampleRate = 24000) {
            const numChannels = 1;
            const bytesPerSample = 2; // 16-bit
            const blockAlign = numChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = pcm16.length * bytesPerSample;
            const buffer = new ArrayBuffer(44 + dataSize); // 44-byte WAV header + data
            const view = new DataView(buffer);
            let offset = 0;

            function writeString(s) {
                for (let i = 0; i < s.length; i++) {
                    view.setUint8(offset + i, s.charCodeAt(i));
                }
                offset += s.length;
            }

            // RIFF chunk
            writeString('RIFF'); // ChunkID
            view.setUint32(offset, 36 + dataSize, true); offset += 4; // ChunkSize
            writeString('WAVE'); // Format

            // FMT sub-chunk
            writeString('fmt '); // Subchunk1ID
            view.setUint32(offset, 16, true); offset += 4; // Subchunk1Size (16 for PCM)
            view.setUint16(offset, 1, true); offset += 2; // AudioFormat (1 for PCM)
            view.setUint16(offset, numChannels, true); offset += 2; // NumChannels
            view.setUint32(offset, sampleRate, true); offset += 4; // SampleRate
            view.setUint32(offset, byteRate, true); offset += 4; // ByteRate
            view.setUint16(offset, blockAlign, true); offset += 2; // BlockAlign
            view.setUint16(offset, bytesPerSample * 8, true); offset += 2; // BitsPerSample

            // DATA sub-chunk
            writeString('data'); // Subchunk2ID
            view.setUint32(offset, dataSize, true); offset += 4; // Subchunk2Size

            // Write PCM data
            for (let i = 0; i < pcm16.length; i++) {
                view.setInt16(offset, pcm16[i], true); // true for little-endian
                offset += 2;
            }

            return new Blob([buffer], { type: 'audio/wav' });
        }

        // Plays audio from a cached Blob URL or plays a mock sound
        function playCachedAudio(audioUrl) {
            if (audioUrl === 'mock') {
                playMockAudio();
                return true;
            }
            if (audioUrl) {
                const audio = new Audio(audioUrl);
                audio.play().catch(e => console.error("Error playing audio:", e));
                return true;
            }
            return false;
        }


        // --- API Call and State Management ---

        function setStatus(message, isLoading = false, type = 'cyan') {
            const statusDiv = document.getElementById('status-message');
            const statusText = document.getElementById('status-text');
            const spinner = document.getElementById('loading-spinner');

            // Using the dark/neon status bar classes
            const statusClasses = {
                'cyan': 'bg-gray-800 border border-cyan-600 text-cyan-400',
                'fuchsia': 'bg-gray-800 border border-fuchsia-600 text-fuchsia-400',
                'error': 'bg-red-900 border border-red-600 text-red-400'
            };
            
            // Apply base classes plus selected neon style
            statusDiv.className = `${statusClasses[type]} px-4 py-3 rounded-md mb-6 shadow-xl`;


            if (isLoading) {
                statusDiv.classList.remove('hidden');
                spinner.classList.remove('hidden');
                statusText.textContent = message;
            } else if (message) {
                statusDiv.classList.remove('hidden');
                spinner.classList.add('hidden');
                statusText.textContent = message;
                setTimeout(() => statusDiv.classList.add('hidden'), 5000); // Hide after 5 seconds
            } else {
                statusDiv.classList.add('hidden');
            }
        }

        async function fetchWithRetry(url, options, maxRetries) {
            for (let i = 0; i < maxRetries; i++) {
                try {
                    const response = await fetch(url, options);
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    return response;
                } catch (error) {
                    console.error(`Fetch attempt ${i + 1} failed:`, error);
                    if (i === maxRetries - 1) throw error;
                    const delay = Math.pow(2, i) * 1000;
                    await new Promise(resolve => setTimeout(resolve, delay));
                }
            }
        }

        // 1. TEXT-TO-SPEECH (TTS) - Fetches and Caches Audio URL
        async function getAudioUrl(symbol, exampleWord) {
            // CHECK CACHE
            if (cache.audioUrls[symbol]) {
                return cache.audioUrls[symbol];
            }
            if (IS_STATIC_HOSTING) return 'mock';

            // --- LIVE API CALL (Only runs in Canvas environment) ---
            const prompt = `Pronounce the IPA sound ${symbol} and say the example word "${exampleWord}" slowly and clearly.`;
            
            const ttsPayload = {
                contents: [{ parts: [{ text: prompt }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Puck" } } }
                },
                model: "gemini-2.5-flash-preview-tts"
            };

            try {
                const response = await fetchWithRetry(TTS_API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(ttsPayload)
                }, MAX_RETRIES);

                const result = await response.json();
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType;

                if (audioData && mimeType && mimeType.startsWith("audio/")) {
                    const rateMatch = mimeType.match(/rate=(\d+)/);
                    const sampleRate = rateMatch ? parseInt(rateMatch[1], 10) : 24000; 
                    
                    const pcmData = base64ToArrayBuffer(audioData);
                    const pcm16 = new Int16Array(pcmData);
                    const wavBlob = pcmToWav(pcm16, sampleRate);
                    const audioUrl = URL.createObjectURL(wavBlob);
                    
                    // STORE IN CACHE
                    cache.audioUrls[symbol] = audioUrl;
                    return audioUrl;
                } else {
                    console.error("TTS audio data missing or invalid format:", result);
                    return null;
                }
            } catch (error) {
                console.error("Error generating TTS audio:", error);
                return null;
            }
        }

        // 2. GOOGLE SEARCH GROUNDING - Fetches and Caches Search Info
        async function searchPhonemeInfo(symbol) {
            // CHECK CACHE
            if (cache.searchInfo[symbol]) {
                return cache.searchInfo[symbol];
            }
            if (IS_STATIC_HOSTING) {
                // Find and return mock data if running statically
                const item = [...ipaSymbols.vowels, ...ipaSymbols.consonants].find(i => i.symbol === symbol);
                return {
                    text: item.mock_desc + " (Mock Data: API calls are disabled for static hosting).",
                    sources: []
                };
            }


            // --- LIVE API CALL (Only runs in Canvas environment) ---
            const systemPrompt = "You are a friendly and precise phonetics instructor. Explain the following IPA sound in a single paragraph, including what type of sound it is (e.g., 'voiced alveolar stop'), and how it is produced. Keep the explanation concise and beginner-friendly.";
            const userQuery = `What is the IPA symbol ${symbol}? Give a short explanation of its pronunciation.`;

            const searchPayload = {
                contents: [{ parts: [{ text: userQuery }] }],
                tools: [{ "google_search": {} }],
                systemInstruction: { parts: [{ text: systemPrompt }] },
            };

            try {
                const response = await fetchWithRetry(SEARCH_API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(searchPayload)
                }, MAX_RETRIES);

                const result = await response.json();
                const candidate = result.candidates?.[0];

                let searchResult = { text: "Could not find a detailed explanation for this sound.", sources: [] };

                if (candidate && candidate.content?.parts?.[0]?.text) {
                    searchResult.text = candidate.content.parts[0].text;
                    const groundingMetadata = candidate.groundingMetadata;

                    if (groundingMetadata && groundingMetadata.groundingAttributions) {
                        searchResult.sources = groundingMetadata.groundingAttributions
                            .map(attribution => ({
                                uri: attribution.web?.uri,
                                title: attribution.web?.title,
                            }))
                            .filter(source => source.uri && source.title);
                    }
                }
                
                // STORE IN CACHE
                cache.searchInfo[symbol] = searchResult;
                return searchResult;

            } catch (error) {
                console.error("Error during Google Search grounding:", error);
                return { text: "An error occurred while fetching live information.", sources: [] };
            }
        }

        // --- Main Handler ---

        async function handleSymbolClick(symbol, exampleWord) {
            if (IS_STATIC_HOSTING) {
                setStatus(`Running in Static Mode. Playing mock audio for /${symbol}/.`, true, 'cyan');
            } else {
                setStatus(`Processing /${symbol}/... Fetching data if needed.`, true);
            }

            const cachedAudioUrl = cache.audioUrls[symbol];
            const cachedSearchResult = cache.searchInfo[symbol];

            let audioUrl = cachedAudioUrl;
            let searchResult = cachedSearchResult;
            
            // 1. DETERMINE FETCH PROMISES
            const fetchPromises = [];
            
            // Only fetch if not cached AND not static hosting
            if (!cachedSearchResult) {
                fetchPromises.push(searchPhonemeInfo(symbol));
            }
            if (!cachedAudioUrl) {
                fetchPromises.push(getAudioUrl(symbol, exampleWord));
            }

            // 2. CONCURRENTLY FETCH MISSING DATA
            if (fetchPromises.length > 0) {
                if (!IS_STATIC_HOSTING) {
                    setStatus(`Fetching new data for /${symbol}/...`, true, 'fuchsia');
                }
                
                const results = await Promise.all(fetchPromises);
                let resultIndex = 0;

                // Assign results based on what was fetched (order matters!)
                if (!cachedSearchResult) {
                    searchResult = results[resultIndex++];
                }
                if (!cachedAudioUrl) {
                    audioUrl = results[resultIndex];
                }
            }
            
            // 3. PLAY AUDIO (newly fetched or cached)
            if (audioUrl) {
                playCachedAudio(audioUrl);
                setStatus(IS_STATIC_HOSTING ? `Mock audio played! Displaying mock details for /${symbol}/.` : `Audio playing! Displaying details for /${symbol}/.`, false, 'cyan');
            } else {
                setStatus(`Could not play audio for /${symbol}/. Displaying details.`, false, 'error');
            }
            
            // 4. DISPLAY RESULTS IN MODAL
            document.getElementById('modal-symbol').textContent = `/${symbol}/`;
            document.getElementById('modal-explanation').textContent = searchResult.text;
            
            // Re-bind the play button to the final audio URL (cached or new)
            const playButton = document.getElementById('modal-play-audio');
            playButton.onclick = () => playCachedAudio(audioUrl);

            // Populate sources
            const sourcesList = document.getElementById('modal-sources');
            sourcesList.innerHTML = '';
            
            if (searchResult.sources && searchResult.sources.length > 0) {
                searchResult.sources.forEach(source => {
                    const li = document.createElement('li');
                    li.innerHTML = `<a href="${source.uri}" target="_blank" class="text-fuchsia-400 hover:text-fuchsia-300 break-words">${source.title || source.uri}</a>`;
                    sourcesList.appendChild(li);
                });
            } else {
                const li = document.createElement('li');
                li.textContent = searchResult.text.includes("Mock Data") ? 'No live sources available in static hosting mode.' : 'No specific web sources found for the explanation.';
                li.className = 'text-gray-500';
                sourcesList.appendChild(li);
            }

            // Show the modal
            document.getElementById('result-modal').classList.remove('hidden');
        }

        function closeModal() {
            document.getElementById('result-modal').classList.add('hidden');
        }

        window.closeModal = closeModal;
    </script>
</body>
</html>
